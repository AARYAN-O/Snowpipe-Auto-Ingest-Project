# Snowpipe Auto Ingest Project

This project demonstrates **continuous ingestion and transformation** of data into Snowflake using:

- **S3 + Storage Integration** (secure external stage)
- **Snowpipe with Auto-ingest** (continuous loading from S3)
- **Streams** (Change Data Capture / CDC)
- **Tasks** (scheduled transformations)

---

## ðŸ“Œ Flow
1. Data arrives in **S3 bucket** â†’ `aaryan-snowflake-project-bucket`
2. **Snowpipe** auto-ingests into **staging table (`ADIDAS_SALES_STG`)**
3. A **Stream** tracks changes in the staging table
4. A **Task** runs every 1 minute, transforming and loading data into the **curated table (`ADIDAS_SALES_CURATED`)**

---

## ðŸ“‚ Folder Structure
- `sql/` â†’ All SQL scripts
- `data/` â†’ Sample CSV file for ingestion

---

## ðŸš€ Steps to Run

### 1. Database & Schema
```sql
CREATE OR REPLACE DATABASE SNOWPIPE_AUTO_INGEST;
USE DATABASE SNOWPIPE_AUTO_INGEST;

CREATE OR REPLACE SCHEMA SNOWPIPE_AUTOINGEST_SCHEMA;


snowpipe-auto-ingest/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_database_schema.sql
â”‚   â”œâ”€â”€ 02_storage_integration.sql
â”‚   â”œâ”€â”€ 03_stage.sql
â”‚   â”œâ”€â”€ 04_pipe.sql
â”‚   â”œâ”€â”€ 05_tables.sql
â”‚   â”œâ”€â”€ 06_streams.sql
â”‚   â””â”€â”€ 07_tasks.sql
â””â”€â”€ data/
    â””â”€â”€ Adidas_US_Sales_Datasets.csv   # sample file to upload to S3

<img width="1911" height="826" alt="image" src="https://github.com/user-attachments/assets/9fe8fce8-b1c0-4311-ae23-e7f319c9d907" />

